{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f71b661",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c60d1c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import sseclient\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ac16e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities :\n",
      "Bob vs. Society (film)\n",
      "Fred Astaire (actor)\n",
      "The Shawshank Redemption (film)\n",
      "Christopher Nolan (director)\n",
      "The Godfather (film)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#entities selection\n",
    "ENTITIES = {\n",
    "    \"bob_vs_society\": {\n",
    "        \"name\": \"Bob vs. Society\",\n",
    "        \"type\": \"film\",\n",
    "        \"wiki_title\": \"Bob_vs._Society\"\n",
    "    },\n",
    "    \"fred_astaire\": {\n",
    "        \"name\": \"Fred Astaire\",\n",
    "        \"type\": \"actor\",\n",
    "        \"wiki_title\": \"Fred_Astaire\"\n",
    "    },\n",
    "    \"shawshank_redemption\": {\n",
    "        \"name\": \"The Shawshank Redemption\",\n",
    "        \"type\": \"film\",\n",
    "        \"wiki_title\": \"The_Shawshank_Redemption\"\n",
    "    },\n",
    "    \"christopher_nolan\": {\n",
    "        \"name\": \"Christopher Nolan\",\n",
    "        \"type\": \"director\",\n",
    "        \"wiki_title\": \"Christopher_Nolan\"\n",
    "    },\n",
    "    \"the_godfather\": {\n",
    "        \"name\": \"The Godfather\",\n",
    "        \"type\": \"film\",\n",
    "        \"wiki_title\": \"The_Godfather\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Entities :\")\n",
    "for key, entity in ENTITIES.items():\n",
    "    print(f\"{entity['name']} ({entity['type']})\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a616bf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics : wikimedia_stream_data\\metrics.csv\n",
      "Alerts : wikimedia_stream_data\\alerts.csv\n",
      "Summary : wikimedia_stream_data\\summary.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = \"wikimedia_stream_data\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "METRICS_FILE = os.path.join(OUTPUT_DIR, \"metrics.csv\")\n",
    "ALERTS_FILE = os.path.join(OUTPUT_DIR, \"alerts.csv\")\n",
    "SUMMARY_FILE = os.path.join(OUTPUT_DIR, \"summary.csv\")\n",
    "\n",
    "print(f\"Metrics : {METRICS_FILE}\")\n",
    "print(f\"Alerts : {ALERTS_FILE}\")\n",
    "print(f\"Summary : {SUMMARY_FILE}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3edfe0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_data = []\n",
    "alerts_data = []\n",
    "\n",
    "summary_stats = defaultdict(lambda: {\n",
    "    \"total_edits\": 0,\n",
    "    \"total_bytes_changed\": 0,\n",
    "    \"unique_users\": set(),\n",
    "    \"anonymous_edits\": 0,\n",
    "    \"major_changes\": 0\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5e26c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_entity_page(title):\n",
    "    #Check if the modified page corresponds to one of our entities\n",
    "    for entity_key, entity_info in ENTITIES.items():\n",
    "        if entity_info['wiki_title'] == title:\n",
    "            return entity_key, entity_info['name']\n",
    "    return None, None\n",
    "\n",
    "def process_change_event(change):\n",
    "    try:\n",
    "        # Check if is  a 'edit' event\n",
    "        if change.get('type') != 'edit':\n",
    "            return None\n",
    "        \n",
    "        # CHeck if is an english page \n",
    "        if change.get('wiki') != 'enwiki':\n",
    "            return None\n",
    "        \n",
    "        title = change.get('title', '').replace(' ', '_')\n",
    "        entity_key, entity_name = is_entity_page(title)\n",
    "        \n",
    "        if entity_key is None:\n",
    "            return None\n",
    "        \n",
    "        # Extract important information\n",
    "        timestamp = datetime.fromtimestamp(change.get('timestamp', 0))\n",
    "        user = change.get('user', 'Unknown')\n",
    "        is_bot = change.get('bot', False)\n",
    "        is_anonymous = 'user' in change and not change.get('user')\n",
    "        bytes_changed = change.get('length', {}).get('new', 0) - change.get('length', {}).get('old', 0)\n",
    "        comment = change.get('comment', '')[:100]\n",
    "        \n",
    "        metric = {\n",
    "            'timestamp': timestamp,\n",
    "            'entity_key': entity_key,\n",
    "            'entity_name': entity_name,\n",
    "            'user': user,\n",
    "            'is_bot': is_bot,\n",
    "            'is_anonymous': is_anonymous,\n",
    "            'bytes_changed': bytes_changed,\n",
    "            'comment': comment\n",
    "        }\n",
    "        \n",
    "        return metric\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error {e}\")\n",
    "        return None\n",
    "\n",
    "def check_for_alerts(metric):\n",
    "    alerts = []\n",
    "    \n",
    "    # Major change\n",
    "    if abs(metric['bytes_changed']) > 1000:\n",
    "        alerts.append({\n",
    "            'timestamp': metric['timestamp'],\n",
    "            'entity_name': metric['entity_name'],\n",
    "            'alert_type': 'MAJOR_CHANGE',\n",
    "            'description': f\"Changement de {metric['bytes_changed']} bytes\",\n",
    "            'user': metric['user']\n",
    "        })\n",
    "    \n",
    "    # Change from a anonymous user\n",
    "    if metric['is_anonymous']:\n",
    "        alerts.append({\n",
    "            'timestamp': metric['timestamp'],\n",
    "            'entity_name': metric['entity_name'],\n",
    "            'alert_type': 'ANONYMOUS_EDIT',\n",
    "            'description': \"Modification par utilisateur anonyme\",\n",
    "            'user': metric['user']\n",
    "        })\n",
    "    \n",
    "    return alerts\n",
    "\n",
    "def update_summary_stats(metric):\n",
    "    key = metric['entity_key']\n",
    "    summary_stats[key]['total_edits'] += 1\n",
    "    summary_stats[key]['total_bytes_changed'] += metric['bytes_changed']\n",
    "    summary_stats[key]['unique_users'].add(metric['user'])\n",
    "    \n",
    "    if metric['is_anonymous']:\n",
    "        summary_stats[key]['anonymous_edits'] += 1\n",
    "    \n",
    "    if abs(metric['bytes_changed']) > 1000:\n",
    "        summary_stats[key]['major_changes'] += 1\n",
    "\n",
    "\n",
    "\n",
    "def save_data():\n",
    "    if metrics_data:\n",
    "        df_metrics = pd.DataFrame(metrics_data)\n",
    "    else:\n",
    "        df_metrics = pd.DataFrame(columns=[\n",
    "            'timestamp', 'entity_key', 'entity_name', 'user', \n",
    "            'is_bot', 'is_anonymous', 'bytes_changed', 'comment'\n",
    "        ])\n",
    "    df_metrics.to_csv(METRICS_FILE, index=False)\n",
    "    print(f\"✓ {len(metrics_data)} métriques sauvegardées\")\n",
    "    \n",
    "    if alerts_data:\n",
    "        df_alerts = pd.DataFrame(alerts_data)\n",
    "    else:\n",
    "        df_alerts = pd.DataFrame(columns=[\n",
    "            'timestamp', 'entity_name', 'alert_type', 'description', 'user'\n",
    "        ])\n",
    "    df_alerts.to_csv(ALERTS_FILE, index=False)\n",
    "    print(f\"✓ {len(alerts_data)} alertes sauvegardées\")\n",
    "\n",
    "    summary_list = []\n",
    "    for entity_key, stats in summary_stats.items():\n",
    "        summary_list.append({\n",
    "            'entity_key': entity_key,\n",
    "            'entity_name': ENTITIES[entity_key]['name'],\n",
    "            'total_edits': stats['total_edits'],\n",
    "            'total_bytes_changed': stats['total_bytes_changed'],\n",
    "            'unique_users': len(stats['unique_users']),\n",
    "            'anonymous_edits': stats['anonymous_edits'],\n",
    "            'major_changes': stats['major_changes']\n",
    "        })\n",
    "    \n",
    "    if summary_list:\n",
    "        df_summary = pd.DataFrame(summary_list)\n",
    "    else:\n",
    "        summary_list = []\n",
    "        for entity_key, entity_info in ENTITIES.items():\n",
    "            summary_list.append({\n",
    "                'entity_key': entity_key,\n",
    "                'entity_name': entity_info['name'],\n",
    "                'total_edits': 0,\n",
    "                'total_bytes_changed': 0,\n",
    "                'unique_users': 0,\n",
    "                'anonymous_edits': 0,\n",
    "                'major_changes': 0\n",
    "            })\n",
    "        df_summary = pd.DataFrame(summary_list)\n",
    "    \n",
    "    df_summary.to_csv(SUMMARY_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80a82f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_stream(duration_seconds=300):\n",
    "    url = 'https://stream.wikimedia.org/v2/stream/recentchange'\n",
    "    headers = {\n",
    "        'User-Agent': 'IMDb-Stream-Project/1.0 (Educational; Contact: votre.email@example.com)',\n",
    "        'Accept': 'text/event-stream'\n",
    "    }\n",
    "    \n",
    "    print(f\"URL : {url}\")\n",
    "    print(f\"Duration : {duration_seconds} seconds\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    event_count = 0\n",
    "    reconnect_count = 0\n",
    "    max_reconnects = 5\n",
    "    \n",
    "    while time.time() - start_time < duration_seconds and reconnect_count < max_reconnects:\n",
    "        try:\n",
    "                       \n",
    "            response = requests.get(\n",
    "                url, \n",
    "                stream=True, \n",
    "                headers=headers,\n",
    "                timeout=60\n",
    "            )\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                print(f\"Erreur HTTP {response.status_code}\")\n",
    "                reconnect_count += 1\n",
    "                continue\n",
    "            buffer = \"\"\n",
    "            \n",
    "            for chunk in response.iter_content(chunk_size=1024, decode_unicode=True):\n",
    "                # Check time\n",
    "                elapsed = time.time() - start_time\n",
    "                if elapsed > duration_seconds:\n",
    "                    return\n",
    "                \n",
    "                if not chunk:\n",
    "                    continue\n",
    "                \n",
    "                buffer += chunk\n",
    "                \n",
    "                while '\\n\\n' in buffer:\n",
    "                    event_text, buffer = buffer.split('\\n\\n', 1)\n",
    "                    \n",
    "                    if not event_text.strip():\n",
    "                        continue\n",
    "                    data_line = None\n",
    "                    for line in event_text.split('\\n'):\n",
    "                        if line.startswith('data: '):\n",
    "                            data_line = line[6:]\n",
    "                            break\n",
    "                    \n",
    "                    if not data_line:\n",
    "                        continue\n",
    "                    \n",
    "                    event_count += 1\n",
    "                    \n",
    "                    if event_count % 100 == 0:\n",
    "                        print(\".\", end=\"\", flush=True)\n",
    "                    \n",
    "                    if event_count == 1:\n",
    "                        print(f\"First event after {elapsed:.1f}s\\n\")\n",
    "                    \n",
    "                    try:\n",
    "                        change = json.loads(data_line)\n",
    "                        \n",
    "                        if event_count % 500 == 0:\n",
    "                            print(f\"{event_count} events\")\n",
    "                            if 'wiki' in change:\n",
    "                                print(f\"   Exemple : {change.get('wiki')} - {change.get('title', 'N/A')}\")\n",
    "                        \n",
    "                        metric = process_change_event(change)\n",
    "                        \n",
    "                        if metric:\n",
    "                            print(f\"   Entity : {metric['entity_name']}\")\n",
    "                            print(f\"   User : {metric['user']}\")\n",
    "                            print(f\"   Change : {metric['bytes_changed']:+d} bytes\\n\")\n",
    "                            \n",
    "                            metrics_data.append(metric)\n",
    "                            \n",
    "                            alerts = check_for_alerts(metric)\n",
    "                            if alerts:\n",
    "                                print(f\"   ⚠️  {len(alerts)} ALERTE(S) !\")\n",
    "                                for alert in alerts:\n",
    "                                    print(f\"      → {alert['alert_type']}\")\n",
    "                                alerts_data.extend(alerts)\n",
    "                            \n",
    "                            update_summary_stats(metric)\n",
    "                            \n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "                    except Exception:\n",
    "                        continue            \n",
    "            break\n",
    "            \n",
    "        except (requests.exceptions.ChunkedEncodingError, \n",
    "                requests.exceptions.ConnectionError,\n",
    "                requests.exceptions.Timeout) as e:\n",
    "            reconnect_count += 1\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error {type(e).__name__}\")\n",
    "            reconnect_count += 1\n",
    "            if reconnect_count >= max_reconnects:\n",
    "                break\n",
    "    save_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1dd68ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL : https://stream.wikimedia.org/v2/stream/recentchange\n",
      "Duration : 30 seconds\n",
      "First event after 1.7s\n",
      "\n",
      ".....500 events\n",
      "   Exemple : wikidatawiki - Q105417433\n",
      "...."
     ]
    }
   ],
   "source": [
    "connect_to_stream(duration_seconds=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "547702f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          entity_key              entity_name  total_edits  total_bytes_changed  unique_users  anonymous_edits  major_changes\n",
      "      bob_vs_society          Bob vs. Society            0                    0             0                0              0\n",
      "        fred_astaire             Fred Astaire            0                    0             0                0              0\n",
      "shawshank_redemption The Shawshank Redemption            0                    0             0                0              0\n",
      "   christopher_nolan        Christopher Nolan            0                    0             0                0              0\n",
      "       the_godfather            The Godfather            0                    0             0                0              0\n",
      "\n",
      "Last Alerts :\n",
      "     No alerts\n",
      "\n",
      "Last change :\n",
      "     No changes\n"
     ]
    }
   ],
   "source": [
    "def analyze_results():\n",
    "\n",
    "    try:\n",
    "        df_metrics = pd.read_csv(METRICS_FILE)\n",
    "        df_alerts = pd.read_csv(ALERTS_FILE)\n",
    "        df_summary = pd.read_csv(SUMMARY_FILE)\n",
    "        \n",
    "        print(df_summary.to_string(index=False))\n",
    "        \n",
    "        print(\"\\nLast Alerts :\")\n",
    "        if len(df_alerts) > 0:\n",
    "            print(df_alerts.tail().to_string(index=False))\n",
    "        else:\n",
    "            print(\"     No alerts\")\n",
    "        \n",
    "        print(\"\\nLast change :\")\n",
    "\n",
    "        if len(df_metrics) > 0:\n",
    "            print(df_metrics[['timestamp', 'entity_name', 'user', 'bytes_changed']].tail().to_string(index=False))\n",
    "        else:\n",
    "            print(\"     No changes\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(\"No data\")\n",
    "analyze_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
